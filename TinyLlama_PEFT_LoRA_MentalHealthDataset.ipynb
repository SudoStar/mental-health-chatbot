{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Update Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.3.1+cu121)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.3.1+cu121)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Using cached huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Using cached safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Installing collected packages: safetensors, huggingface-hub, accelerate\n",
      "Successfully installed accelerate-1.2.0 huggingface-hub-0.26.3 safetensors-0.4.5\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 tokenizers-0.21.0 transformers-4.47.0\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.3.1+cu121)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.47.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.2.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.26.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.14.0\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading aiohttp-3.11.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.1/344.1 kB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, propcache, multiprocess, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 datasets-3.1.0 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade peft\n",
    "!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Depenedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:14:49.045958Z",
     "iopub.status.busy": "2024-11-29T16:14:49.045562Z",
     "iopub.status.idle": "2024-11-29T16:14:49.050152Z",
     "shell.execute_reply": "2024-11-29T16:14:49.049161Z",
     "shell.execute_reply.started": "2024-11-29T16:14:49.045914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model and Tokenizer\n",
    "\n",
    "The following cells sets  up a lightweight language model (TinyLlama) for natural language processing tasks, with a focuses on Memory Efficiency with 8-bit quantization, maps the model to devices if more than one GPU is being used, and gives the limited hardware the ability to process and generate text and fine-tune the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:31:03.918682Z",
     "iopub.status.busy": "2024-11-29T16:31:03.917846Z",
     "iopub.status.idle": "2024-11-29T16:31:07.452374Z",
     "shell.execute_reply": "2024-11-29T16:31:07.451502Z",
     "shell.execute_reply.started": "2024-11-29T16:31:03.918644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d9f98c14064204bd25a6398a2c676c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5c67a129f14e808b8c2a32a678c7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8171a6c7f94e4e829eefbec907c38027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe3b3fd1fd84877831453ccd5ce807e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b1c4e69d6749d48ef90a0e9f28cb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e524a7391f4f56b9da28cae51403d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef31ff967742659054d176af95706d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\", padding_side=\"right\",)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_8bit=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\", device_map=\"auto\", quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:31:14.366824Z",
     "iopub.status.busy": "2024-11-29T16:31:14.366437Z",
     "iopub.status.idle": "2024-11-29T16:31:41.287024Z",
     "shell.execute_reply": "2024-11-29T16:31:41.286075Z",
     "shell.execute_reply.started": "2024-11-29T16:31:14.366790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
      "\n",
      "###INPUT: What does it mean to have a mental illness?\n",
      "\n",
      "###PROMPT: What is the difference between a mental illness and a mental disorder?\n",
      "\n",
      "###PROMPT: What is the difference between a mental disorder and a mental illness?\n",
      "\n",
      "###PROMPT: What is the difference between a mental disorder and a mental illness?\n",
      "\n",
      "###PROMPT: What is the difference between a mental illness and a mental disorder?\n",
      "\n",
      "###PROMPT: What is the difference between a mental disorder and a mental illness?\n",
      "\n",
      "###PROMPT: What is the difference between a mental illness and a mental disorder?\n",
      "\n",
      "###PROMPT: What is the difference between a mental disorder and a mental illness?\n",
      "\n",
      "###PROMPT: What is the difference between a mental illness and a mental disorder?\n",
      "\n",
      "###PROMPT: What is the difference between a mental disorder and a mental illness?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
    "\n",
    "###INPUT: What does it mean to have a mental illness?\n",
    "\n",
    "###PROMPT:\"\"\"\n",
    "tokens = tokenizer(txt, return_tensors=\"pt\")['input_ids'].to(\"cuda\")\n",
    "op = model.generate(tokens, max_new_tokens=200)\n",
    "print(tokenizer.decode(op[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the PEFT Model\n",
    "\n",
    "The following cells prepares a pre-trained language model that can use parameter-efficient tuning (PEFT) with the assistance of LoRA(Low-Rank Adaptation), that focuses on efficiently finetuning and training a small subset of the modfel parameters in which efficiency and accuracy will not be compromised and sacrficed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:31:41.445751Z",
     "iopub.status.busy": "2024-11-29T16:31:41.445470Z",
     "iopub.status.idle": "2024-11-29T16:31:41.522387Z",
     "shell.execute_reply": "2024-11-29T16:31:41.521510Z",
     "shell.execute_reply.started": "2024-11-29T16:31:41.445723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "#r value is important as it dictates the size of the model and the amount of finetuning parameters\n",
    "peft_config = LoraConfig(inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, peft_type=TaskType.CAUSAL_LM)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:31:51.956810Z",
     "iopub.status.busy": "2024-11-29T16:31:51.956454Z",
     "iopub.status.idle": "2024-11-29T16:31:51.962124Z",
     "shell.execute_reply": "2024-11-29T16:31:51.961068Z",
     "shell.execute_reply.started": "2024-11-29T16:31:51.956778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_dataset(data_point):\n",
    "    prompt = f\"\"\"###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
    "\n",
    "###INPUT: {data_point['Questions']}\n",
    "\n",
    "###PROMPT: {data_point['Answers']}\n",
    "\"\"\"\n",
    "    tokens = tokenizer(prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",)\n",
    "    tokens[\"labels\"] = tokens['input_ids'].copy()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Load the Dataset\n",
    "\n",
    "This prepares the chosen dataset that can be found in the same folder as the ipynb code. The code below also tokenizes and cleans up the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/mental-health-chatbot\n"
     ]
    }
   ],
   "source": [
    "# make sure to cd to the correct directory\n",
    "%cd mental-health-chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:39:21.143663Z",
     "iopub.status.busy": "2024-11-29T16:39:21.143240Z",
     "iopub.status.idle": "2024-11-29T16:39:21.155440Z",
     "shell.execute_reply": "2024-11-29T16:39:21.154484Z",
     "shell.execute_reply.started": "2024-11-29T16:39:21.143630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mentalhealth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:42:58.319677Z",
     "iopub.status.busy": "2024-11-29T16:42:58.319063Z",
     "iopub.status.idle": "2024-11-29T16:42:58.473429Z",
     "shell.execute_reply": "2024-11-29T16:42:58.472459Z",
     "shell.execute_reply.started": "2024-11-29T16:42:58.319641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a37635d944f4ec895ef3edd761a1f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33e72f5d9f54ce98bf7b17d4b0f6298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Question_ID', 'Questions', 'Answers', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 77\n",
      "}) Dataset({\n",
      "    features: ['Question_ID', 'Questions', 'Answers', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "train_d = Dataset.from_pandas(train_dataset)\n",
    "test_d = Dataset.from_pandas(test_dataset)\n",
    "\n",
    "train_d = train_d.map(format_dataset)\n",
    "test_d = test_d.map(format_dataset)\n",
    "print(train_d, test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:43:04.728349Z",
     "iopub.status.busy": "2024-11-29T16:43:04.727667Z",
     "iopub.status.idle": "2024-11-29T16:43:04.738591Z",
     "shell.execute_reply": "2024-11-29T16:43:04.737529Z",
     "shell.execute_reply.started": "2024-11-29T16:43:04.728313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
      "\n",
      "###INPUT: What’s the difference between dissociative identity disorder (multiple personality disorder) and schizophrenia?\n",
      "\n",
      "###PROMPT: Sometimes, people confuse dissociative identity disorder, formerly known as multiple personality disorder, and schizophrenia. Schizophrenia does mean “split mind,” but the name was meant to describe the ‘split’ from reality that you experience during an episode of psychosis, as well as changes in thoughts, emotions, and other functions. Dissociative identity disorder, on the other hand, does cause a split or fragmented understanding of a person’s sense of themselves. \n",
      " Dissociative identity disorder is really more about fragmented identities than many different personalities that develop on their own. Most people see different parts of their being as part of the whole person. For people who experience DID, identity fragments may have very different characteristics, including their own history, identity, and mannerisms. A key part of DID is dissociation—feeling detached to the world around you. People who experience DID may have many unexplainable gaps in their memory, forget information they’re already learned, or have difficulties recalling things they’ve said or done. Unlike portrayals of DID on TV or in movies, DID may not be obvious to others, and it can take a lot of time to come to the diagnosis. \n",
      " Schizophrenia is a serious mental illness that causes hallucinations (sensations that aren’t real) and delusions (beliefs that can’t possibly be true, in addition to other symptoms like jumbled thoughts, jumbled speech, and difficulties expressing emotions. People who experience schizophrenia may hear or feel things that aren’t real or believe things that can’t be real, but these aren’t separate identities.\n",
      "</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_d[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:43:35.428647Z",
     "iopub.status.busy": "2024-11-29T16:43:35.427715Z",
     "iopub.status.idle": "2024-11-29T16:43:35.435314Z",
     "shell.execute_reply": "2024-11-29T16:43:35.434351Z",
     "shell.execute_reply.started": "2024-11-29T16:43:35.428609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Question_ID', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 77\n",
      "}) Dataset({\n",
      "    features: ['Question_ID', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_d = train_d.remove_columns(['Questions', \"Answers\"])\n",
    "test_d = test_d.remove_columns(['Questions', \"Answers\"])\n",
    "print(train_d, test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question_ID': 7984793,\n",
       " '__index_level_0__': 85,\n",
       " 'input_ids': [1,\n",
       "  835,\n",
       "  14816,\n",
       "  1254,\n",
       "  12665,\n",
       "  29901,\n",
       "  16564,\n",
       "  373,\n",
       "  2672,\n",
       "  12336,\n",
       "  3611,\n",
       "  5706,\n",
       "  278,\n",
       "  9508,\n",
       "  363,\n",
       "  1176,\n",
       "  1230,\n",
       "  1904,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  1177,\n",
       "  12336,\n",
       "  29901,\n",
       "  1724,\n",
       "  30010,\n",
       "  29879,\n",
       "  278,\n",
       "  4328,\n",
       "  1546,\n",
       "  766,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  313,\n",
       "  20787,\n",
       "  2022,\n",
       "  2877,\n",
       "  766,\n",
       "  2098,\n",
       "  29897,\n",
       "  322,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  29973,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  29925,\n",
       "  3491,\n",
       "  7982,\n",
       "  29901,\n",
       "  18512,\n",
       "  29892,\n",
       "  2305,\n",
       "  1970,\n",
       "  1509,\n",
       "  766,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  21510,\n",
       "  2998,\n",
       "  408,\n",
       "  2999,\n",
       "  2022,\n",
       "  2877,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  322,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  29889,\n",
       "  1102,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  947,\n",
       "  2099,\n",
       "  1346,\n",
       "  5451,\n",
       "  3458,\n",
       "  3995,\n",
       "  541,\n",
       "  278,\n",
       "  1024,\n",
       "  471,\n",
       "  6839,\n",
       "  304,\n",
       "  8453,\n",
       "  278,\n",
       "  5129,\n",
       "  5451,\n",
       "  30010,\n",
       "  515,\n",
       "  16832,\n",
       "  393,\n",
       "  366,\n",
       "  7271,\n",
       "  2645,\n",
       "  385,\n",
       "  12720,\n",
       "  310,\n",
       "  11643,\n",
       "  19263,\n",
       "  29892,\n",
       "  408,\n",
       "  1532,\n",
       "  408,\n",
       "  3620,\n",
       "  297,\n",
       "  13133,\n",
       "  29892,\n",
       "  23023,\n",
       "  1080,\n",
       "  29892,\n",
       "  322,\n",
       "  916,\n",
       "  3168,\n",
       "  29889,\n",
       "  3295,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  373,\n",
       "  278,\n",
       "  916,\n",
       "  1361,\n",
       "  29892,\n",
       "  947,\n",
       "  4556,\n",
       "  263,\n",
       "  6219,\n",
       "  470,\n",
       "  9376,\n",
       "  287,\n",
       "  8004,\n",
       "  310,\n",
       "  263,\n",
       "  2022,\n",
       "  30010,\n",
       "  29879,\n",
       "  4060,\n",
       "  310,\n",
       "  6053,\n",
       "  29889,\n",
       "  29871,\n",
       "  13,\n",
       "  3295,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  338,\n",
       "  2289,\n",
       "  901,\n",
       "  1048,\n",
       "  9376,\n",
       "  287,\n",
       "  2893,\n",
       "  1907,\n",
       "  1135,\n",
       "  1784,\n",
       "  1422,\n",
       "  7333,\n",
       "  1907,\n",
       "  393,\n",
       "  2693,\n",
       "  373,\n",
       "  1009,\n",
       "  1914,\n",
       "  29889,\n",
       "  7849,\n",
       "  2305,\n",
       "  1074,\n",
       "  1422,\n",
       "  5633,\n",
       "  310,\n",
       "  1009,\n",
       "  1641,\n",
       "  408,\n",
       "  760,\n",
       "  310,\n",
       "  278,\n",
       "  3353,\n",
       "  2022,\n",
       "  29889,\n",
       "  1152,\n",
       "  2305,\n",
       "  1058,\n",
       "  7271,\n",
       "  360,\n",
       "  1367,\n",
       "  29892,\n",
       "  10110,\n",
       "  22370,\n",
       "  1122,\n",
       "  505,\n",
       "  1407,\n",
       "  1422,\n",
       "  21862,\n",
       "  29892,\n",
       "  3704,\n",
       "  1009,\n",
       "  1914,\n",
       "  4955,\n",
       "  29892,\n",
       "  10110,\n",
       "  29892,\n",
       "  322,\n",
       "  8214,\n",
       "  12903,\n",
       "  29889,\n",
       "  319,\n",
       "  1820,\n",
       "  760,\n",
       "  310,\n",
       "  360,\n",
       "  1367,\n",
       "  338,\n",
       "  766,\n",
       "  2839,\n",
       "  362,\n",
       "  30003,\n",
       "  1725,\n",
       "  14067,\n",
       "  1439,\n",
       "  3791,\n",
       "  304,\n",
       "  278,\n",
       "  3186,\n",
       "  2820,\n",
       "  366,\n",
       "  29889,\n",
       "  11647,\n",
       "  1058,\n",
       "  7271,\n",
       "  360,\n",
       "  1367,\n",
       "  1122,\n",
       "  505,\n",
       "  1784,\n",
       "  443,\n",
       "  4548,\n",
       "  7420,\n",
       "  519,\n",
       "  330,\n",
       "  2547,\n",
       "  297,\n",
       "  1009,\n",
       "  3370,\n",
       "  29892,\n",
       "  9566,\n",
       "  2472,\n",
       "  896,\n",
       "  30010,\n",
       "  276,\n",
       "  2307,\n",
       "  10972,\n",
       "  29892,\n",
       "  470,\n",
       "  505,\n",
       "  23553,\n",
       "  17386,\n",
       "  292,\n",
       "  2712,\n",
       "  896,\n",
       "  30010,\n",
       "  345,\n",
       "  1497,\n",
       "  470,\n",
       "  2309,\n",
       "  29889,\n",
       "  853,\n",
       "  4561,\n",
       "  2011,\n",
       "  764,\n",
       "  1338,\n",
       "  310,\n",
       "  360,\n",
       "  1367,\n",
       "  373,\n",
       "  5648,\n",
       "  470,\n",
       "  297,\n",
       "  2351,\n",
       "  583,\n",
       "  29892,\n",
       "  360,\n",
       "  1367,\n",
       "  1122,\n",
       "  451,\n",
       "  367,\n",
       "  6924,\n",
       "  304,\n",
       "  4045,\n",
       "  29892,\n",
       "  322,\n",
       "  372,\n",
       "  508,\n",
       "  2125,\n",
       "  263,\n",
       "  3287,\n",
       "  310,\n",
       "  931,\n",
       "  304,\n",
       "  2041,\n",
       "  304,\n",
       "  278,\n",
       "  24876,\n",
       "  19263,\n",
       "  29889,\n",
       "  29871,\n",
       "  13,\n",
       "  1102,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  338,\n",
       "  263,\n",
       "  10676,\n",
       "  19119,\n",
       "  4486,\n",
       "  2264,\n",
       "  393,\n",
       "  9946,\n",
       "  12713,\n",
       "  1682,\n",
       "  262,\n",
       "  800,\n",
       "  313,\n",
       "  23149,\n",
       "  800,\n",
       "  393,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  1855,\n",
       "  29897,\n",
       "  322,\n",
       "  628,\n",
       "  375,\n",
       "  1080,\n",
       "  313,\n",
       "  6596,\n",
       "  2575,\n",
       "  29879,\n",
       "  393,\n",
       "  508,\n",
       "  30010,\n",
       "  29873,\n",
       "  10075,\n",
       "  367,\n",
       "  1565,\n",
       "  29892,\n",
       "  297,\n",
       "  6124,\n",
       "  304,\n",
       "  916,\n",
       "  25828,\n",
       "  4835,\n",
       "  763,\n",
       "  432,\n",
       "  25443,\n",
       "  13133,\n",
       "  29892,\n",
       "  432,\n",
       "  25443,\n",
       "  12032,\n",
       "  29892,\n",
       "  322,\n",
       "  23553,\n",
       "  4653,\n",
       "  292,\n",
       "  23023,\n",
       "  1080,\n",
       "  29889,\n",
       "  11647,\n",
       "  1058,\n",
       "  7271,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  1122,\n",
       "  8293,\n",
       "  470,\n",
       "  4459,\n",
       "  2712,\n",
       "  393,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  1855,\n",
       "  470,\n",
       "  4658,\n",
       "  2712,\n",
       "  393,\n",
       "  508,\n",
       "  30010,\n",
       "  29873,\n",
       "  367,\n",
       "  1855,\n",
       "  29892,\n",
       "  541,\n",
       "  1438,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  5004,\n",
       "  2893,\n",
       "  1907,\n",
       "  29889,\n",
       "  13,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [1,\n",
       "  835,\n",
       "  14816,\n",
       "  1254,\n",
       "  12665,\n",
       "  29901,\n",
       "  16564,\n",
       "  373,\n",
       "  2672,\n",
       "  12336,\n",
       "  3611,\n",
       "  5706,\n",
       "  278,\n",
       "  9508,\n",
       "  363,\n",
       "  1176,\n",
       "  1230,\n",
       "  1904,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  1177,\n",
       "  12336,\n",
       "  29901,\n",
       "  1724,\n",
       "  30010,\n",
       "  29879,\n",
       "  278,\n",
       "  4328,\n",
       "  1546,\n",
       "  766,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  313,\n",
       "  20787,\n",
       "  2022,\n",
       "  2877,\n",
       "  766,\n",
       "  2098,\n",
       "  29897,\n",
       "  322,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  29973,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  29925,\n",
       "  3491,\n",
       "  7982,\n",
       "  29901,\n",
       "  18512,\n",
       "  29892,\n",
       "  2305,\n",
       "  1970,\n",
       "  1509,\n",
       "  766,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  21510,\n",
       "  2998,\n",
       "  408,\n",
       "  2999,\n",
       "  2022,\n",
       "  2877,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  322,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  29889,\n",
       "  1102,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  947,\n",
       "  2099,\n",
       "  1346,\n",
       "  5451,\n",
       "  3458,\n",
       "  3995,\n",
       "  541,\n",
       "  278,\n",
       "  1024,\n",
       "  471,\n",
       "  6839,\n",
       "  304,\n",
       "  8453,\n",
       "  278,\n",
       "  5129,\n",
       "  5451,\n",
       "  30010,\n",
       "  515,\n",
       "  16832,\n",
       "  393,\n",
       "  366,\n",
       "  7271,\n",
       "  2645,\n",
       "  385,\n",
       "  12720,\n",
       "  310,\n",
       "  11643,\n",
       "  19263,\n",
       "  29892,\n",
       "  408,\n",
       "  1532,\n",
       "  408,\n",
       "  3620,\n",
       "  297,\n",
       "  13133,\n",
       "  29892,\n",
       "  23023,\n",
       "  1080,\n",
       "  29892,\n",
       "  322,\n",
       "  916,\n",
       "  3168,\n",
       "  29889,\n",
       "  3295,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  29892,\n",
       "  373,\n",
       "  278,\n",
       "  916,\n",
       "  1361,\n",
       "  29892,\n",
       "  947,\n",
       "  4556,\n",
       "  263,\n",
       "  6219,\n",
       "  470,\n",
       "  9376,\n",
       "  287,\n",
       "  8004,\n",
       "  310,\n",
       "  263,\n",
       "  2022,\n",
       "  30010,\n",
       "  29879,\n",
       "  4060,\n",
       "  310,\n",
       "  6053,\n",
       "  29889,\n",
       "  29871,\n",
       "  13,\n",
       "  3295,\n",
       "  2839,\n",
       "  1230,\n",
       "  10110,\n",
       "  766,\n",
       "  2098,\n",
       "  338,\n",
       "  2289,\n",
       "  901,\n",
       "  1048,\n",
       "  9376,\n",
       "  287,\n",
       "  2893,\n",
       "  1907,\n",
       "  1135,\n",
       "  1784,\n",
       "  1422,\n",
       "  7333,\n",
       "  1907,\n",
       "  393,\n",
       "  2693,\n",
       "  373,\n",
       "  1009,\n",
       "  1914,\n",
       "  29889,\n",
       "  7849,\n",
       "  2305,\n",
       "  1074,\n",
       "  1422,\n",
       "  5633,\n",
       "  310,\n",
       "  1009,\n",
       "  1641,\n",
       "  408,\n",
       "  760,\n",
       "  310,\n",
       "  278,\n",
       "  3353,\n",
       "  2022,\n",
       "  29889,\n",
       "  1152,\n",
       "  2305,\n",
       "  1058,\n",
       "  7271,\n",
       "  360,\n",
       "  1367,\n",
       "  29892,\n",
       "  10110,\n",
       "  22370,\n",
       "  1122,\n",
       "  505,\n",
       "  1407,\n",
       "  1422,\n",
       "  21862,\n",
       "  29892,\n",
       "  3704,\n",
       "  1009,\n",
       "  1914,\n",
       "  4955,\n",
       "  29892,\n",
       "  10110,\n",
       "  29892,\n",
       "  322,\n",
       "  8214,\n",
       "  12903,\n",
       "  29889,\n",
       "  319,\n",
       "  1820,\n",
       "  760,\n",
       "  310,\n",
       "  360,\n",
       "  1367,\n",
       "  338,\n",
       "  766,\n",
       "  2839,\n",
       "  362,\n",
       "  30003,\n",
       "  1725,\n",
       "  14067,\n",
       "  1439,\n",
       "  3791,\n",
       "  304,\n",
       "  278,\n",
       "  3186,\n",
       "  2820,\n",
       "  366,\n",
       "  29889,\n",
       "  11647,\n",
       "  1058,\n",
       "  7271,\n",
       "  360,\n",
       "  1367,\n",
       "  1122,\n",
       "  505,\n",
       "  1784,\n",
       "  443,\n",
       "  4548,\n",
       "  7420,\n",
       "  519,\n",
       "  330,\n",
       "  2547,\n",
       "  297,\n",
       "  1009,\n",
       "  3370,\n",
       "  29892,\n",
       "  9566,\n",
       "  2472,\n",
       "  896,\n",
       "  30010,\n",
       "  276,\n",
       "  2307,\n",
       "  10972,\n",
       "  29892,\n",
       "  470,\n",
       "  505,\n",
       "  23553,\n",
       "  17386,\n",
       "  292,\n",
       "  2712,\n",
       "  896,\n",
       "  30010,\n",
       "  345,\n",
       "  1497,\n",
       "  470,\n",
       "  2309,\n",
       "  29889,\n",
       "  853,\n",
       "  4561,\n",
       "  2011,\n",
       "  764,\n",
       "  1338,\n",
       "  310,\n",
       "  360,\n",
       "  1367,\n",
       "  373,\n",
       "  5648,\n",
       "  470,\n",
       "  297,\n",
       "  2351,\n",
       "  583,\n",
       "  29892,\n",
       "  360,\n",
       "  1367,\n",
       "  1122,\n",
       "  451,\n",
       "  367,\n",
       "  6924,\n",
       "  304,\n",
       "  4045,\n",
       "  29892,\n",
       "  322,\n",
       "  372,\n",
       "  508,\n",
       "  2125,\n",
       "  263,\n",
       "  3287,\n",
       "  310,\n",
       "  931,\n",
       "  304,\n",
       "  2041,\n",
       "  304,\n",
       "  278,\n",
       "  24876,\n",
       "  19263,\n",
       "  29889,\n",
       "  29871,\n",
       "  13,\n",
       "  1102,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  338,\n",
       "  263,\n",
       "  10676,\n",
       "  19119,\n",
       "  4486,\n",
       "  2264,\n",
       "  393,\n",
       "  9946,\n",
       "  12713,\n",
       "  1682,\n",
       "  262,\n",
       "  800,\n",
       "  313,\n",
       "  23149,\n",
       "  800,\n",
       "  393,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  1855,\n",
       "  29897,\n",
       "  322,\n",
       "  628,\n",
       "  375,\n",
       "  1080,\n",
       "  313,\n",
       "  6596,\n",
       "  2575,\n",
       "  29879,\n",
       "  393,\n",
       "  508,\n",
       "  30010,\n",
       "  29873,\n",
       "  10075,\n",
       "  367,\n",
       "  1565,\n",
       "  29892,\n",
       "  297,\n",
       "  6124,\n",
       "  304,\n",
       "  916,\n",
       "  25828,\n",
       "  4835,\n",
       "  763,\n",
       "  432,\n",
       "  25443,\n",
       "  13133,\n",
       "  29892,\n",
       "  432,\n",
       "  25443,\n",
       "  12032,\n",
       "  29892,\n",
       "  322,\n",
       "  23553,\n",
       "  4653,\n",
       "  292,\n",
       "  23023,\n",
       "  1080,\n",
       "  29889,\n",
       "  11647,\n",
       "  1058,\n",
       "  7271,\n",
       "  1364,\n",
       "  466,\n",
       "  459,\n",
       "  13608,\n",
       "  423,\n",
       "  1122,\n",
       "  8293,\n",
       "  470,\n",
       "  4459,\n",
       "  2712,\n",
       "  393,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  1855,\n",
       "  470,\n",
       "  4658,\n",
       "  2712,\n",
       "  393,\n",
       "  508,\n",
       "  30010,\n",
       "  29873,\n",
       "  367,\n",
       "  1855,\n",
       "  29892,\n",
       "  541,\n",
       "  1438,\n",
       "  9455,\n",
       "  30010,\n",
       "  29873,\n",
       "  5004,\n",
       "  2893,\n",
       "  1907,\n",
       "  29889,\n",
       "  13,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Training Model\n",
    "\n",
    "Key Terms:\n",
    "    tokenizer - converts raw text into token IDs that the model can understand\n",
    "    \n",
    "    data_collator - prepares batches of data for training. Padding sequences to the same length and handling any other          preprocessing that is needed to prepare a batch of data\n",
    "\n",
    "    remove_unused_columns=False - We have intentionally prepared the dataset so that this function won't be needed. \n",
    "\n",
    "    per_device_train_batch_size=2 - The batch size used per device (GPU or CPU) during training. Determines how many samples are processed before the model's weights are updated\n",
    "\n",
    "    gradient_checkpointing=True - Drastically reduce memory usage, allowing you to train large models on smaller devices or with larger batch sizes.\n",
    "\n",
    "    gradient_accumulation_steps=4 - Used when you want to simulate a larger batch size without using too much GPU memory.\n",
    "\n",
    "    max_steps - also known as epochs\n",
    "\n",
    "    learning_rate=2.5e-5 -  learning rate for the optimizer\n",
    "\n",
    "    logging_steps=5 This controls how often training statistics (e.g., loss, accuracy) are logged.\n",
    "\n",
    "    fp16=True - Using half-precision floating point (FP16) can significantly speed up training and reduce memory usage\n",
    "\n",
    "    optim=\"paged_adamw_8bit\" - optimizer to use during training\n",
    "\n",
    "    save_strategy=\"steps\" - Saving checkpoints regularly allows you to restore training in case of interruptions.\n",
    "\n",
    "    save_steps=50 - Number of steps between each checkpoint save.\n",
    "\n",
    "    report_to=\"none\" - When you don’t need external monitoring tools or want to save computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:43:38.484663Z",
     "iopub.status.busy": "2024-11-29T16:43:38.483560Z",
     "iopub.status.idle": "2024-11-29T16:43:38.489204Z",
     "shell.execute_reply": "2024-11-29T16:43:38.488065Z",
     "shell.execute_reply.started": "2024-11-29T16:43:38.484620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.device_count() > 1: \n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:43:43.685382Z",
     "iopub.status.busy": "2024-11-29T16:43:43.684241Z",
     "iopub.status.idle": "2024-11-29T16:43:45.219322Z",
     "shell.execute_reply": "2024-11-29T16:43:45.218316Z",
     "shell.execute_reply.started": "2024-11-29T16:43:43.685342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135/1071746114.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "                    model = model, \n",
    "                    train_dataset=train_d, \n",
    "                    eval_dataset=test_d,\n",
    "                    tokenizer = tokenizer, \n",
    "                    data_collator = data_collator, \n",
    "\n",
    "                    args = TrainingArguments(\n",
    "                        output_dir=\"./training\",\n",
    "                        remove_unused_columns=False,\n",
    "                        per_device_train_batch_size=12,\n",
    "                        max_steps=20,\n",
    "                        logging_steps=5,\n",
    "                        fp16=True,\n",
    "                        save_strategy=\"steps\",     \n",
    "                        save_steps=50,           \n",
    "                        report_to = \"none\",\n",
    "                        \n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "The code below sets up the necessary training environment for fine-tuning a language model using the HuggingFace's Trainer method alongside user-chosen parameters that will effectively and efficiently train the model to produce the desired results.\n",
    "\n",
    "The modes was successfully trained on multiple systems: Kaggle Notebook using the T4 X2 GPU, on a Linux System with an RTX 2060 GPU and on the HSLU's JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T16:43:58.198449Z",
     "iopub.status.busy": "2024-11-29T16:43:58.197184Z",
     "iopub.status.idle": "2024-11-29T17:19:42.406847Z",
     "shell.execute_reply": "2024-11-29T17:19:42.406109Z",
     "shell.execute_reply.started": "2024-11-29T16:43:58.198410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 02:27, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.416000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.4459938049316405, metrics={'train_runtime': 156.087, 'train_samples_per_second': 1.538, 'train_steps_per_second': 0.128, 'total_flos': 719015009845248.0, 'train_loss': 1.4459938049316405, 'epoch': 2.857142857142857})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text Responses\n",
    "\n",
    "The code below shows a prompt that the user can ask the AI Chatbot about mental health. The Chatbot will then output a helpful yet grammar-correct response that the user can understand and learn from. The same with the training method.\n",
    "\n",
    "Bandi et al (2023) highlights how important user feedback is in evaluating the performance of generative-based AI chatbots, especially those focused on mental health. While technical and numerical metrics help measure how well the chatbot's response are on paper, user-centric evaluations such as how helpful the chatbot is, whether it answers questions clearly, and how satisfied users feel, are more practical metrics.\n",
    "\n",
    "Since chatbot conversations can change depending on the context, listening to user feedback is key to improving its responses and making sure it meets real-world needs effectively.\n",
    "\n",
    "https://www.mdpi.com/1999-5903/15/8/260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:24:16.627104Z",
     "iopub.status.busy": "2024-11-29T17:24:16.626404Z",
     "iopub.status.idle": "2024-11-29T17:24:57.327055Z",
     "shell.execute_reply": "2024-11-29T17:24:57.326166Z",
     "shell.execute_reply.started": "2024-11-29T17:24:16.627067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
      "\n",
      "###INPUT: What does it mean to have a mental illness?\n",
      "\n",
      "###PROMPT: A mental illness is a problem with your mind, your thoughts, your emotions, or your behaviour.\n",
      "\n",
      "Many people think of mental illness as a problem with your brain. But your brain is just one part of your body. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions of cells. Your brain is made up of billions\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
    "\n",
    "###INPUT: What does it mean to have a mental illness?\n",
    "\n",
    "###PROMPT:\"\"\"\n",
    "tokens = tokenizer(txt, return_tensors=\"pt\")['input_ids'].to(\"cuda\")\n",
    "op = model.generate(tokens, max_new_tokens=200)\n",
    "print(tokenizer.decode(op[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "The code below saves the model allowing the user to share and reload the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tinyllama_peft_mentalhealth\", safe_serialization=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score\n",
    "\n",
    "In the following section, the BLEU score (as explained in the first Jupyter Notebook) for this model is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_answers = []\n",
    "\n",
    "for question in test_dataset['Questions']:\n",
    "    txt = \"\"\"###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
    "\n",
    "    ###INPUT: {input}\n",
    "\n",
    "    ###PROMPT:\"\"\".format(input=question)\n",
    "    tokens = tokenizer(txt, return_tensors=\"pt\")['input_ids'].to(\"cuda\")\n",
    "    op = model.generate(tokens, max_new_tokens=200)\n",
    "    pred_answers.append(tokenizer.decode(op[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6851366</td>\n",
       "      <td>What's the difference between a psychiatrist a...</td>\n",
       "      <td>A psychiatrist is a medical doctor with extra ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Question_ID                                          Questions  \\\n",
       "58      6851366  What's the difference between a psychiatrist a...   \n",
       "\n",
       "                                              Answers  \n",
       "58  A psychiatrist is a medical doctor with extra ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> ###SYSTEM: Based on INPUT title generate the prompt for generative model\\n\\n    ###INPUT: What's the difference between a psychiatrist and a registered psychologist?\\n\\n    ###PROMPT: A psychiatrist is a doctor who specializes in mental health. A registered psychologist is a doctor who has completed a post-graduate program in psychology and is licensed to practice in BC.\\n\\n    ###PROMPT: A registered psychologist is a doctor who has completed a post-graduate program in psychology and is licensed to practice in BC.\\n\\n    ###SOURCE: http://www.bccareers.bc.ca/health-professions/psychology/\\n\\n### Psychology: What is Psychotherapy?\\n\\nPsychotherapy is a form of treatment that uses talk therapy to help people deal with problems or difficulties. It can be used to help people deal with problems or difficulties that are causing problems in their lives. It can also be used to help people deal with problems or difficulties that are not causing problems in their lives. Psychotherapy can be used to help people deal with\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_answers = []\n",
    "for _, row in test_dataset.iterrows():\n",
    "    txt = \"\"\"###SYSTEM: Based on INPUT title generate the prompt for generative model\n",
    "\n",
    "    ###INPUT: {input}\n",
    "\n",
    "    ###PROMPT: {prompt}\"\"\".format(input=row['Questions'], prompt=row['Answers'])\n",
    "\n",
    "    expected_answers.append([txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"###SYSTEM: Based on INPUT title generate the prompt for generative model\\n\\n    ###INPUT: What's the difference between a psychiatrist and a registered psychologist?\\n\\n    ###PROMPT: A psychiatrist is a medical doctor with extra training in mental health who can choose to prescribe medications. Some use psychotherapy (‘talk therapies’) approaches like cognitive-behavioural therapy to treat mental health problems. Many psychiatrists work at hospitals, clinics, or health centres, and some have a private office. As they are specialist doctors, you will almost always need another doctor’s referral to see a psychiatrist, and fees are covered by MSP. If you have a valid BC Services or CareCard, you do not need to pay to see a psychiatrist. \\n A registered psychologist focuses on different talk therapy or counselling approaches to treatments, but they don’t prescribe medication. They have graduate degrees in psychology. There are two different ways to access registered psychologists: the public system and the private system. Registered psychologists in the public system work in some hospitals or schools. You may need a doctor’s referral to access the program, and costs are usually covered by MSP. However, most people need to access registered psychologists through the private system. To do this, you can contact the psychologist yourself—you do not need a referral. Costs are not covered by MSP, but they may be covered by employee health plans. A registered psychologist’s fees charged by hour vary, and some offer lower fees to people with lower incomes. \\n You’ve probably noticed that a lot of the differences come down to how you pay for different services and how these professionals are educated. The practical differences in how they work are not always so clear. When it comes to your treatment and care, the most important part is finding a professional who supports your own goals. Are you really focused on fine-tuning medications? Are you looking for a particular therapy approach? Does the professional’s philosophy of care make sense to you? Do you like the professional you’re talking to and do you feel safe sharing your experiences? Ultimately, your relationship with the professional is what matters. Instead of focusing on designation, look for a professional who meets your needs and your expectations. \\n Talk to your family doctor and ask for their recommendations \\n Ask local mental health organizations for help. You can find local branches through the provincial organizations behind HeretoHelp \\n Ask a community health centre, outpatient psychiatry program, or mental health team for suggestions \\n For a list of psychiatrists near you, search under ‘Specialist’ in the College of Physicians and Surgeons of British Columbia’s Find a Physician Tool but remember that you will first need a referral from a doctor (like your family doctor) \\n For a list of psychologists near you, search in the British Columbia Psychological Association’s Find a Registered Psychologist tool and you can also learn more about finding a psychologist from the College of Psychologists of British Columbia\"]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.26.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "\n",
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=pred_answers, references=expected_answers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The achieved BLEU score of 0.119 of this third model is far better than the 0.006 of the second model. It is not particularly impressive, but considering the limited number of samples used, the results are satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.11899107417616166,\n",
       " 'precisions': [0.4032216160041569,\n",
       "  0.21337163750326457,\n",
       "  0.17931215542137044,\n",
       "  0.1689100026392188],\n",
       " 'brevity_penalty': 0.5266571518373007,\n",
       " 'length_ratio': 0.609308215925281,\n",
       " 'translation_length': 3849,\n",
       " 'reference_length': 6317}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "When comparing results, the Tiny-Llama model delivers much better responses than both the original and improved generative-based models shown in the first notebook. When comparing the Tiny-Llama model with a QLora Falcon model, the Tiny-Llama model uses far fewer hardware resources and runs easily on a free Kaggle or Google Colab notebook. In contrast, the QLoRA Falcon model, for example, requires a state-of-the-art NVIDIA A100 GPU.\n",
    "\n",
    "This fine-tuned model based on Tiny-Llama shows that it is possible to create an effective mental health chatbot with only small amounts of data. Despite Llama2 having 6 times as many parameters as Tiny-Llama, its performance is similar (Nguyen, 2024). Furthermore, innovations like LoRA make it easier to design custom, high-performing chatbots for mental health support by reducing the number of trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Improvements\n",
    "\n",
    "Future improvements could focus on incorporating a larger dataset, leading to less overfitting and the inclusion of a wider range of topics, such as healthcare or other specialized domains. Expanding the dataset would not only enhance the model's scope but also improve its ability to generalize across various use cases. Additionally, further fine-tuning the model could help in minimizing training loss."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 903283,
     "sourceId": 1531926,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
